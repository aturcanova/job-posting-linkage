{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Record Linkage - Blocking\n",
    "\n",
    "In this notebook, we use Record Linkage to match the JobPostings and Orbis datasets using purely SortedNeighborhood Index.\n",
    "\n",
    "The notebook is organized in the following fashion:\n",
    "\n",
    "0. Import libraries and define constants\n",
    "1. Upload parts of JobPostings dataset\n",
    "2. Upload parts of Orbis dataset\n",
    "3. Records to match\n",
    "4. Blocking on ZIP code and Name\n",
    "5. Blocking on ZIP code\n",
    "6. Blocking on City and Name\n",
    "7. Blocking on partial ZIP codes\n",
    "8. Blocking on City\n",
    "9. Blocking on Bundeslands\n",
    "10. SortedNeighbourhoodIndex on name\n",
    "11. ECM \n",
    "12. Save processed data\n",
    "13. NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import recordlinkage\n",
    "# Import jellyfish.cjellyfish for record linkage\n",
    "import jellyfish.cjellyfish # The import checks if C-version of string comparision of recordlinkage is installed\n",
    "\n",
    "from linkage.model.utils import save_dataframe, read_dataframe\n",
    "from linkage.model.record_matching import Linking, print_matched_counts, print_unmatched_counts\n",
    "from linkage.model.record_linkage_utils import CompareZipCodes, CompareString\n",
    "from linkage.model.examine_dataframe import print_dataframe_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two types of data, all or the first part (part01.rar)\n",
    "# part01 is used for implementation purposes \n",
    "# To check if everything is working as it sould\n",
    "TYPE = 'all'  # 'all' or 'part01'\n",
    "\n",
    "# 'std' for standardized, 'std_dict_40k' for dictionary cleaning with the 40k most common words\n",
    "NOTE = 'std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify paths to data directories\n",
    "PROCESSED_JP_DIR = f\"../data/processed/jobpostings\"\n",
    "PROCESSED_ORBIS_DIR = f\"../data/processed/orbis/{TYPE}\"\n",
    "PROCESSED_DATA_DIR = f\"../data/processed/linkage/{TYPE}\"\n",
    "\n",
    "# Specifie file names to read from\n",
    "JP_FILE = f'jobpostings_test_sample_std_dict_40k.csv'\n",
    "ORBIS_NAME_FILE = f'orbis_german_bvid_name_processed_{TYPE}_{NOTE}.csv'\n",
    "ORBIS_ADDR_FILE = f'orbis_german_all_addresses_processed_{TYPE}_{NOTE}.csv' #'orbis_german_all_addresses_clean.csv'\n",
    "\n",
    "LINKED_DF = \"linked_matches.csv\"\n",
    "\n",
    "# Columns\n",
    "# JobPostings\n",
    "JP_INDEX = 'jobposting_id'\n",
    "JP_COMPANY_NAME, JP_COMPANY_NAME_STANDARDIZED, JP_COMPANY_NAME_DICT_CLEANED = 'company', 'company_standard', 'company_dict_clean'\n",
    "JP_COMPANY_CITY, JP_COMPANY_ZIP, JP_COMPANY_STATE = 'company_city', 'company_zipcode', 'company_state'\n",
    "JP_JOB_CITY, JP_JOB_ZIP, JP_JOB_STATE = 'job_city', 'job_zipcode', 'job_state'\n",
    "\n",
    "# Orbis\n",
    "ORBIS_INDEX = 'BvD ID number'\n",
    "ORBIS_COMPANY_NAME, ORBIS_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_DICT_CLEANED = 'NAME', 'NAME_standard', 'NAME_dict_clean'\n",
    "ORBIS_COMPANY_CITY, ORBIS_COMPANY_ZIP, ORBIS_COMPANY_STATE = 'City (native)', 'Postcode', 'Region in country'\n",
    "\n",
    "# Files for the partial results \n",
    "COMPANY_ZIP_NAME_EXACT = f\"linked_matches_blocking_company_zip-name_exact_{TYPE}_{NOTE}.csv\"\n",
    "COMPANY_ZIP_NAME_EX_SIMILAR = f\"linked_matches_blocking_company_zip-name_similar_name_{TYPE}_{NOTE}.csv\"\n",
    "COMPANY_ZIP_NAME_SIMILAR = f\"linked_matches_blocking_company_zip-name_similar_{TYPE}_{NOTE}.csv\"\n",
    "JOB_ZIP_NAME_SIMILAR = f\"linked_matches_blocking_job_zip-name_similar_{TYPE}_{NOTE}.csv\"\n",
    "\n",
    "COMPANY_ZIP_SIMILAR = f\"linked_matches_blocking_company_zipcode_similar_{TYPE}_{NOTE}.csv\"\n",
    "JOB_ZIP_SIMILAR = f\"linked_matches_blocking_job_zipcode_similar_{TYPE}_{NOTE}.csv\"\n",
    "\n",
    "COMPANY_CITY_NAME_SIMILAR = f\"linked_matches_blocking_company_city-name_similar_{TYPE}_{NOTE}.csv\"\n",
    "JOB_CITY_NAME_SIMILAR = f\"linked_matches_blocking_job_city-name_similar_{TYPE}_{NOTE}.csv\"\n",
    "\n",
    "COMPANY_CITY_SIMILAR = f\"linked_matches_blocking_company_city_similar_{TYPE}_{NOTE}.csv\"\n",
    "JOB_CITY_SIMILAR = f\"linked_matches_blocking_job_city_similar_{TYPE}_{NOTE}.csv\"\n",
    "\n",
    "COMPANY_PART_ZIP_SIMILAR = f\"linked_matches_blocking_partial_company_zipcode_similar_{TYPE}_{NOTE}.csv\"\n",
    "JOB_PART_ZIP_SIMILAR = f\"linked_matches_blocking_partial_job_zipcode_similar_{TYPE}_{NOTE}.csv\"\n",
    "\n",
    "COMPANY_STATE_SIMILAR = f\"linked_matches_blocking_company_state_similar_{TYPE}_{NOTE}.csv\"\n",
    "JOB_STATE_SIMILAR = f\"linked_matches_blocking_job_state_similar_{TYPE}_{NOTE}.csv\"\n",
    "\n",
    "SORTED_NN_MATCHING_COMPANY = f\"linked_matches_sorted_neighbourhood_index_company_{TYPE}_{NOTE}.csv\"\n",
    "SORTED_NN_MATCHING_JOB = f\"linked_matches_sorted_neighbourhood_index_job_{TYPE}_{NOTE}.csv\"\n",
    "ECM_MATCHING = f\"linked_matches_ecm_{TYPE}_{NOTE}.csv\"\n",
    "\n",
    "NOT_MATCHED = \"not_matched_blocking.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload parts of JobPostings dataset\n",
    "\n",
    "The preprocessed JobPostings dataset is stored on path:\n",
    "```python\n",
    "../data/processed/jobpostings/\n",
    "```\n",
    "\n",
    "The data are read into Pandas **DataFrame**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp = read_dataframe(PROCESSED_JP_DIR, JP_FILE, JP_INDEX)\n",
    "df_jp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Upload parts of Orbis dataset\n",
    "\n",
    "The preprocessed Orbis dataset is stored on path:\n",
    "```python\n",
    "../data/processed/orbis/\n",
    "```\n",
    "\n",
    "The data are read into Pandas **DataFrame**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read the company name dataframe\n",
    "\n",
    "We read the file containing Orbis company names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_orbis_name = read_dataframe(PROCESSED_ORBIS_DIR, ORBIS_NAME_FILE)\n",
    "df_orbis_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read the company addresses dataframe\n",
    "\n",
    "We read the file containing Orbis company addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_orbis_addresses = read_dataframe(PROCESSED_ORBIS_DIR, ORBIS_ADDR_FILE)\n",
    "df_orbis_addresses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the Orbis dataframes\n",
    "\n",
    "We join Orbis parts to create one dataframe.\n",
    "\n",
    "Note: BvD ID number in addresses' dataframe is not unique.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_orbis = df_orbis_name.merge(df_orbis_addresses, on=ORBIS_INDEX, how='inner')\n",
    "df_orbis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dataframe\n",
    "\n",
    "We check some values of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataframe_length(df_orbis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do in orbis-name notebook\n",
    "df_orbis.rename(columns={\"company_standard\": \"NAME_standard\", \"company_dict_clean\": \"NAME_dict_clean\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the states in Orbis\n",
    "df_orbis[ORBIS_COMPANY_STATE].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the states in JobPostings\n",
    "df_jp[JP_COMPANY_STATE].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_orbis = df_orbis.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orbis index\n",
    "\n",
    "Change name of the Orbis index (it is not the _BvD ID_ because of the missing uniqueness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the index for joining\n",
    "# JP dataset has unique index, therefore is set during the .csv reading\n",
    "df_orbis.index.name = 'orbis_index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Records to match\n",
    "\n",
    "Print the number of unmatched records and initialize a linking class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_unmatched_counts(df_jp, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class containing methods for record linkage\n",
    "linking = Linking(JP_INDEX, JP_COMPANY_NAME, JP_COMPANY_NAME_STANDARDIZED, JP_COMPANY_NAME_DICT_CLEANED,\n",
    "                  JP_COMPANY_CITY, JP_COMPANY_ZIP, JP_COMPANY_STATE,\n",
    "                  JP_JOB_CITY, JP_JOB_ZIP, JP_JOB_STATE,\n",
    "                  ORBIS_INDEX, ORBIS_COMPANY_NAME, ORBIS_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_DICT_CLEANED,\n",
    "                  ORBIS_COMPANY_CITY, ORBIS_COMPANY_ZIP, ORBIS_COMPANY_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Blocking on ZIP code and Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Orbis - Add a column for blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orbis['zip_and_name'] = df_orbis[ORBIS_COMPANY_ZIP].str[:1] + df_orbis[ORBIS_COMPANY_NAME_STANDARDIZED].str.replace(' ', '').str[:3]\n",
    "df_orbis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JobPostings - Add column for blocking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp['zip_and_name'] = df_jp[JP_COMPANY_ZIP].str[:1] + df_jp[JP_COMPANY_NAME_STANDARDIZED].str.replace(' ', '').str[:3]\n",
    "df_jp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Blocking on company ZIP code and Name - Exact matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block('zip_and_name') # exact match on specified columns\n",
    "\n",
    "# Make record pairs\n",
    "candidate_links = indexer.index(df_jp, df_orbis)\n",
    "\n",
    "print(f'Num of candidates: {len(candidate_links)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compare_names = recordlinkage.Compare()\n",
    "\n",
    "compare_names.exact(JP_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_STANDARDIZED, label='company_name_exact')\n",
    "compare_names.exact(JP_COMPANY_ZIP, ORBIS_COMPANY_ZIP, label='company_zipcode_exact')\n",
    "compare_names.exact(JP_COMPANY_CITY, ORBIS_COMPANY_CITY, label='company_city_exact')\n",
    "compare_names.exact(JP_COMPANY_STATE, ORBIS_COMPANY_STATE, label='company_state_exact')\n",
    "\n",
    "features_name = compare_names.compute(candidate_links, df_jp, df_orbis)\n",
    "\n",
    "# Sum the comparison results.\n",
    "features_name.sum(axis=1).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get potential matches\n",
    "potential_matches_name = features_name[features_name.sum(axis=1) == 4] #.reset_index()\n",
    "\n",
    "print(f\"Num. of potential matches by name: {len(potential_matches_name)}\")\n",
    "\n",
    "potential_matches_name = linking.get_best_match(potential_matches_name, JP_INDEX, 'orbis_index')\n",
    "\n",
    "df_merge_name = potential_matches_name.merge(df_jp, how='left', left_on=JP_INDEX, right_on=JP_INDEX)\n",
    "df_merge_name = df_merge_name.merge(df_orbis, how='left', left_on='orbis_index', right_on='orbis_index')\n",
    "\n",
    "df_merge_name = df_merge_name.drop_duplicates([JP_INDEX, ORBIS_INDEX])\n",
    "print(f\"Num. of best matches by name: {len(df_merge_name)}\")\n",
    "\n",
    "df_merge_name_result = df_merge_name[[JP_INDEX, ORBIS_INDEX,\n",
    "                                      JP_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_STANDARDIZED,\n",
    "                                      JP_COMPANY_CITY, ORBIS_COMPANY_CITY,\n",
    "                                      JP_COMPANY_ZIP, ORBIS_COMPANY_ZIP,\n",
    "                                      JP_COMPANY_STATE, ORBIS_COMPANY_STATE]].copy()\n",
    "\n",
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, COMPANY_ZIP_NAME_EXACT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add matches to a new df\n",
    "matched_df = df_merge_name_result.copy()\n",
    "matched_df.set_index([JP_INDEX, ORBIS_INDEX], inplace=True)\n",
    "\n",
    "# Remove matches from old JobPostings dataframe\n",
    "df_jp.drop(df_merge_name_result[JP_INDEX], axis=0, inplace=True)\n",
    "\n",
    "print_matched_counts(matched_df, JP_COMPANY_NAME_STANDARDIZED)\n",
    "print_unmatched_counts(df_jp, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Blocking on company ZIP code and Name - Similarity on name, exact on address\n",
    "\n",
    "Numeric similarity on zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.block('zip_and_name') # exact match on specified columns\n",
    "\n",
    "# Make record pairs\n",
    "candidate_links = indexer.index(df_jp, df_orbis)\n",
    "\n",
    "print(f'Num of candidates: {len(candidate_links)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compare_names = recordlinkage.Compare()\n",
    "\n",
    "compare_names.string(JP_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_STANDARDIZED, \n",
    "                     threshold=0.95, method='jarowinkler', label='company_name_similar')\n",
    "compare_names.exact(JP_COMPANY_ZIP, ORBIS_COMPANY_ZIP, label='company_zipcode_exact')\n",
    "compare_names.exact(JP_COMPANY_CITY, ORBIS_COMPANY_CITY, label='company_city_exact')\n",
    "compare_names.exact(JP_COMPANY_STATE, ORBIS_COMPANY_STATE, label='company_state_exact')\n",
    "features_name = compare_names.compute(candidate_links, df_jp, df_orbis)\n",
    "\n",
    "# Sum the comparison results.\n",
    "features_name.sum(axis=1).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get potential matches\n",
    "potential_matches_name = features_name[features_name.sum(axis=1) == 4]#.reset_index()\n",
    "\n",
    "print(f\"Num. of potential matches by name: {len(potential_matches_name)}\")\n",
    "\n",
    "potential_matches_name = linking.get_best_match(potential_matches_name, JP_INDEX, 'orbis_index')\n",
    "\n",
    "df_merge_name = potential_matches_name.merge(df_jp, how='left', left_on=JP_INDEX, right_on=JP_INDEX)\n",
    "df_merge_name = df_merge_name.merge(df_orbis, how='left', left_on='orbis_index', right_on='orbis_index')\n",
    "\n",
    "df_merge_name = df_merge_name.drop_duplicates([JP_INDEX, ORBIS_INDEX])\n",
    "print(f\"Num. of best matches by name: {len(df_merge_name)}\")\n",
    "\n",
    "df_merge_name_result = df_merge_name[[JP_INDEX, ORBIS_INDEX,\n",
    "                                      JP_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_STANDARDIZED,\n",
    "                                      JP_COMPANY_CITY, ORBIS_COMPANY_CITY,\n",
    "                                      JP_COMPANY_ZIP, ORBIS_COMPANY_ZIP,\n",
    "                                      JP_COMPANY_STATE, ORBIS_COMPANY_STATE]].copy()\n",
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, COMPANY_ZIP_NAME_EX_SIMILAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  Blocking on company ZIP code and Name - All similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, 'zip_and_name')\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='company')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, COMPANY_ZIP_NAME_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop auxiliary columns\n",
    "df_jp.drop(['zip_and_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on job ZIP code and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp['zip_and_name'] = df_jp[JP_JOB_ZIP].str[:1] + df_jp[JP_COMPANY_NAME_STANDARDIZED].str.replace(' ', '').str[:3]\n",
    "df_jp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, 'zip_and_name')\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='job')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, JOB_ZIP_NAME_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop auxiliary columns\n",
    "df_jp.drop(['zip_and_name'], axis=1, inplace=True)\n",
    "df_orbis.drop(['zip_and_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Blocking on ZIP code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on company ZIP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, JP_COMPANY_ZIP, ORBIS_COMPANY_ZIP)\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='company')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, COMPANY_ZIP_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on job ZIP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, JP_JOB_ZIP, ORBIS_COMPANY_ZIP)\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='job')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, JOB_ZIP_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Blocking on City and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orbis['city_and_name'] = df_orbis[ORBIS_COMPANY_CITY].str[:2] + df_orbis[ORBIS_COMPANY_NAME_STANDARDIZED].str.replace(' ', '').str[:3]\n",
    "df_orbis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on company City and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp['city_and_name'] = df_jp[JP_COMPANY_CITY].str[:2] + df_jp[JP_COMPANY_NAME_STANDARDIZED].str.replace(' ', '').str[:3]\n",
    "df_jp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, 'city_and_name')\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='company')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, COMPANY_CITY_NAME_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop auxiliary columns\n",
    "df_jp.drop(['city_and_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on job City and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp['city_and_name'] = df_jp[JP_JOB_CITY].str[:2] + df_jp[JP_COMPANY_NAME_STANDARDIZED].str.replace(' ', '').str[:3]\n",
    "df_jp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, 'city_and_name')\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='job')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, JOB_CITY_NAME_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop auxiliary columns\n",
    "df_jp.drop(['city_and_name'], axis=1, inplace=True)\n",
    "df_orbis.drop(['city_and_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Blocking on partial ZIP codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_num = 4\n",
    "\n",
    "df_orbis['partial_zip'] = df_orbis[ORBIS_COMPANY_ZIP].str[:partial_num]\n",
    "df_orbis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on partial company ZIP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp['partial_company_zip'] = df_jp[JP_COMPANY_ZIP].str[:partial_num]\n",
    "df_jp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, 'partial_company_zip', 'partial_zip')\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='company')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, COMPANY_PART_ZIP_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop auxiliary columns\n",
    "df_jp.drop(['partial_company_zip'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on partial job ZIP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp['partial_job_zip'] = df_jp[JP_JOB_ZIP].str[:partial_num]\n",
    "df_jp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, 'partial_job_zip', 'partial_zip')\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='job')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, JOB_PART_ZIP_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop auxiliary columns\n",
    "df_jp.drop(['partial_job_zip'], axis=1, inplace=True)\n",
    "df_orbis.drop(['partial_zip'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Blocking on City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on company City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, JP_COMPANY_CITY, ORBIS_COMPANY_CITY)\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='company')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, COMPANY_CITY_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on job City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, JP_JOB_CITY, ORBIS_COMPANY_CITY)\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='job')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, JOB_CITY_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 9. Blocking on Bundeslands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on company state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, JP_COMPANY_STATE, ORBIS_COMPANY_STATE)\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='company')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, COMPANY_STATE_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking on job state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candidate pairs\n",
    "candidate_links = linking.blocking(df_jp, df_orbis, JP_JOB_STATE, ORBIS_COMPANY_STATE)\n",
    "\n",
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='job')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, JOB_STATE_SIMILAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 10. SortedNeighbourhoodIndex on name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "indexer = recordlinkage.SortedNeighbourhoodIndex(JP_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_STANDARDIZED, window=7) # NN match on specified columns\n",
    "\n",
    "# Make record pairs\n",
    "candidate_links = indexer.index(df_jp, df_orbis)\n",
    "\n",
    "print(f'Num of candidates: {len(candidate_links)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='company')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, SORTED_NN_MATCHING_COMPANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "indexer = recordlinkage.SortedNeighbourhoodIndex(JP_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_STANDARDIZED, window=7) # NN match on specified columns\n",
    "\n",
    "# Make record pairs\n",
    "candidate_links = indexer.index(df_jp, df_orbis)\n",
    "\n",
    "print(f'Num of candidates: {len(candidate_links)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare fields of candidate pairs\n",
    "features_name = linking.compare_similar_records(df_jp, df_orbis, candidate_links, addr_type='job')\n",
    "\n",
    "# Filter candidate pairs\n",
    "df_merge_name_result = linking.merge_dataframes_on_linkage_result(features_name, df_jp, df_orbis, addr_type='job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, SORTED_NN_MATCHING_JOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process matched and not matched records\n",
    "linking.process_matched(df_jp, matched_df, df_merge_name_result, JP_COMPANY_NAME_STANDARDIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ECM \n",
    "\n",
    "Expectation Conditional Maximization is an unsupervised classification methof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_orbis_ecm = df_orbis.rename(columns={\"NAME\": \"company\", # TODO: change to company name std. and dict. clean\n",
    "                                        \"NAME_standard\": \"company_standard\",\n",
    "                                        \"NAME_dict_clean\": \"company_dict_clean\",\n",
    "                                  \"City (native)\": \"company_city\",\n",
    "                                 \"Region in country\": \"company_state\",\n",
    "                                  \"Postcode\": \"company_zipcode\"\n",
    "                                 }).copy()\n",
    "\n",
    "df_orbis_ecm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "indexer = recordlinkage.SortedNeighbourhoodIndex(JP_COMPANY_NAME_STANDARDIZED, window=7) # NN match on specified columns\n",
    "\n",
    "# Make record pairs\n",
    "candidate_links = indexer.index(df_jp, df_orbis_ecm)\n",
    "\n",
    "print(f'Num of candidates: {len(candidate_links)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compare_names = recordlinkage.Compare()\n",
    "\n",
    "compare_names.string(JP_COMPANY_NAME_STANDARDIZED, JP_COMPANY_NAME_STANDARDIZED, threshold=0.8, method='jarowinkler', label='company_name_similar')\n",
    "#compare_names.add(CompareZipCodes(JP_COMPANY_ZIP, ORBIS_COMPANY_ZIP, label='company_zipcode_similar'))\n",
    "compare_names.string(JP_COMPANY_CITY, JP_COMPANY_CITY,  threshold=0.9, method='jarowinkler', label='company_city_similar')\n",
    "compare_names.string(JP_COMPANY_STATE, JP_COMPANY_STATE, threshold=0.9, method='jarowinkler', label='company_state_similar')\n",
    "\n",
    "features_name = compare_names.compute(candidate_links, df_jp, df_orbis_ecm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ecm = recordlinkage.ECMClassifier()\n",
    "potential_matches_name = ecm.fit_predict(features_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_jp.loc[potential_matches_name[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_orbis_ecm.loc[potential_matches_name[1][1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_matches_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "potential_matches_name = potential_matches_name.to_frame()\n",
    "\n",
    "potential_matches_name = potential_matches_name.rename(columns={\"jobposting_id\": \"col1\", \"orbis_index\": \"col2\"}).copy()\n",
    "\n",
    "potential_matches_name = potential_matches_name.reset_index()\n",
    "\n",
    "potential_matches_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Num. of potential matches by name: {len(potential_matches_name)}\")\n",
    "\n",
    "df_merge_name = potential_matches_name.merge(df_jp, how='left', left_on='jobposting_id', right_on='jobposting_id')\n",
    "df_merge_name = df_merge_name.merge(df_orbis, how='left', left_on='orbis_index', right_on='orbis_index')\n",
    "\n",
    "df_merge_name_result = df_merge_name[[JP_INDEX, ORBIS_INDEX,\n",
    "                                      JP_COMPANY_NAME_STANDARDIZED, ORBIS_COMPANY_NAME_STANDARDIZED,\n",
    "                                      JP_COMPANY_CITY, ORBIS_COMPANY_CITY,\n",
    "                                      JP_COMPANY_ZIP, ORBIS_COMPANY_ZIP,\n",
    "                                      JP_COMPANY_STATE, ORBIS_COMPANY_STATE]].copy()\n",
    "df_merge_name_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataframe to a csv file\n",
    "save_dataframe(df_merge_name_result, PROCESSED_DATA_DIR, ECM_MATCHING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save processed data\n",
    "\n",
    "The processed data is stored in a csv file on a path:\n",
    "```python\n",
    "../data/processed/linkage/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe(matched_df, PROCESSED_DATA_DIR, LINKED_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save not-matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe(pd.DataFrame(df_jp[JP_COMPANY_NAME].unique()), PROCESSED_DATA_DIR, NOT_MATCHED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. NaN values\n",
    "\n",
    "Check records containing NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JobPostings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name_nan = len(df_jp[df_jp[JP_COMPANY_NAME_STANDARDIZED].isna()])\n",
    "\n",
    "print(f\"Company names NaN: {company_name_nan}\")\n",
    "\n",
    "company_city_nan = len(df_jp[df_jp[JP_COMPANY_CITY].isna()])\n",
    "\n",
    "print(f\"Company city NaN: {company_city_nan}\")\n",
    "\n",
    "company_state_nan = len(df_jp[df_jp[JP_COMPANY_STATE].isna()])\n",
    "\n",
    "print(f\"Company state NaN: {company_state_nan}\")\n",
    "\n",
    "company_zipcode_nan = len(df_jp[df_jp[JP_COMPANY_ZIP].isna()])\n",
    "\n",
    "print(f\"Company zipcode NaN: {company_zipcode_nan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any row that contains NaN\n",
    "is_NaN = df_jp.isnull()\n",
    "rows_with_NaN = len(df_jp[is_NaN.any(axis=1)])\n",
    "print(f\"Records with NaN: {rows_with_NaN}\")\n",
    "\n",
    "rows_all_NaN = len(df_jp[is_NaN.all(axis=1)])\n",
    "print(f\"Records only NaN: {rows_all_NaN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orbis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name_nan = len(df_orbis[df_orbis[ORBIS_COMPANY_NAME_STANDARDIZED].isna()])\n",
    "\n",
    "print(f\"Company names NaN: {company_name_nan}\")\n",
    "\n",
    "company_city_nan = len(df_orbis[df_orbis[ORBIS_COMPANY_CITY].isna()])\n",
    "\n",
    "print(f\"Company city NaN: {company_city_nan}\")\n",
    "\n",
    "company_state_nan = len(df_orbis[df_orbis[ORBIS_COMPANY_STATE].isna()])\n",
    "\n",
    "print(f\"Company state NaN: {company_state_nan}\")\n",
    "\n",
    "company_zipcode_nan = len(df_orbis[df_orbis[ORBIS_COMPANY_ZIP].isna()])\n",
    "\n",
    "print(f\"Company zipcode NaN: {company_zipcode_nan}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any row that contains NaN\n",
    "is_NaN = df_orbis.isnull()\n",
    "rows_with_NaN = len(df_orbis[is_NaN.any(axis=1)])\n",
    "print(f\"Records with NaN: {rows_with_NaN}\")\n",
    "\n",
    "rows_all_NaN = len(df_orbis[is_NaN.all(axis=1)])\n",
    "print(f\"Records only NaN: {rows_all_NaN}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

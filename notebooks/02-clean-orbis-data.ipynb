{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Orbis Data\n",
    "\n",
    "This is an **old version** for pre-processing of Orbis data files.\n",
    "\n",
    "Here, we used _Overviews_ to retrieve information about which companies are German.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyunpack\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load parts of Orbis dataset\n",
    "\n",
    "The Orbis dataset is stored on path:\n",
    "```python\n",
    "../data/raw/orbis/\n",
    "```\n",
    "\n",
    "The data are read into Pandas **DataFrame**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the .rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create intermediate data directory if does not exist\n",
    "data_intermediate_dir = '../data/intermediate/orbis'\n",
    "os.makedirs(data_intermediate_dir, exist_ok=True)\n",
    "\n",
    "overviews_rar = '../data/raw/orbis/Overviews.rar'\n",
    "\n",
    "# Unrar rar file to the intermediate directory\n",
    "pyunpack.Archive(overviews_rar).extractall(data_intermediate_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overviews_path = '../data/intermediate/orbis/Overviews.txt'\n",
    "\n",
    "# Read the large file with specified chunksize \n",
    "df_chunk = pd.read_csv(overviews_path, nrows=5,\n",
    "                       error_bad_lines=False, \n",
    "                       sep='\\t')\n",
    "\n",
    "df_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter by the country\n",
    "\n",
    "The information about the **main domestic country** and the **main foreign countries or regions** and other interesting values are stored in the Overviews.rar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_list = []  # append each chunk df here \n",
    "\n",
    "# Read the large file with specified chunksize \n",
    "df_chunk = pd.read_csv(overviews_path, chunksize=1000,\n",
    "                       error_bad_lines=False,\n",
    "                       sep='\\t')\n",
    "\n",
    "for chunk in df_chunk:\n",
    "    # Define filter to get rows where ID starts with 'DE'\n",
    "    bvd_id_filter = chunk['BvD ID number'].str.match('^DE.*') == True\n",
    "    \n",
    "     # Get the rows containing words 'Germany' or 'Deutschland'\n",
    "    id_chunk = chunk[bvd_id_filter]\n",
    "    \n",
    "    # Append filtered chunk\n",
    "    chunk_list.append(id_chunk)\n",
    "    \n",
    "    # Remove matched from chunk\n",
    "    chunk = chunk[~chunk['BvD ID number'].isin(id_chunk['BvD ID number'])]\n",
    "    \n",
    "    for column_name in chunk.columns:\n",
    "        # Define filter to get rows which contains 'Germany' or 'Deutschland'\n",
    "        german_filter = chunk[column_name].astype(str).str.contains(r'Germany|Deutschland') == True\n",
    "\n",
    "        # Get the rows containing words 'Germany' or 'Deutschland'\n",
    "        german_chunk = chunk[german_filter]\n",
    "\n",
    "        # Append filtered chunk\n",
    "        chunk_list.append(german_chunk)\n",
    "        \n",
    "        # Remove matched from chunk\n",
    "        chunk = chunk[~chunk['BvD ID number'].isin(german_chunk['BvD ID number'])]\n",
    "\n",
    "# Concatenate all the filtered chunks\n",
    "df_concat = pd.concat(chunk_list)\n",
    "\n",
    "df_concat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Check interesting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows where BvD ID does not match DE\n",
    "new_df = df_concat[~df_concat['BvD ID number'].str.match('^DE.*')== True]\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get unique Main domestic country values\n",
    "df_concat['Main domestic country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check column values\n",
    "\n",
    "Check values in the different columns to choose the useful columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names\n",
    "column_names = df_concat.columns \n",
    "\n",
    "# Get number of the columns\n",
    "print(f\"Number of the columns: {len(column_names)}\")\n",
    "\n",
    "# Check the number of rows\n",
    "print(f\"Number of rows: {len(df_concat)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Get column data types\n",
    "print(df_concat.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the uniqeness and NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the column is unique\n",
    "for i in column_names:\n",
    "  print(f'{i} is unique: {df_concat[i].is_unique}')\n",
    "\n",
    "# Check the index values\n",
    "# Results in error if there is no index\n",
    "df_concat.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any row that contains NaN\n",
    "row_contains_NaN = df_concat.isnull().any(axis=1)\n",
    "print(f\"Row contains NaN: {len(df_concat[row_contains_NaN])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any row that contains only NaN\n",
    "row_is_NaN = df_concat.isnull().all(axis=1)\n",
    "print(f\"Row is NaN: {len(df_concat[row_is_NaN])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Save the BvD ID of German companies\n",
    "\n",
    "\n",
    "The processed data is stored in a csv file on a path:\n",
    "```python\n",
    "../data/intermediate/orbis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_take = [0]  # Take BvID column\n",
    "\n",
    "new_df = df_concat.take(columns_to_take, axis=1)\n",
    "\n",
    "print(f'Num. of rows: {len(new_df)}')\n",
    "\n",
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "intermediate_dir = \"../data/intermediate/orbis\"\n",
    "df_file = \"orbis_german_bvid.csv\"\n",
    "\n",
    "# Create parent directory if does not exist\n",
    "os.makedirs(intermediate_dir, exist_ok=True)\n",
    "\n",
    "# Save dataframe to a csv file\n",
    "new_df.to_csv(os.path.join(intermediate_dir, df_file), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Remove intermediate file\n",
    "\n",
    "Remove _Overview.txt_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Delete intermediate file\n",
    "os.remove(overviews_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
